{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting training data from the ODC\n",
    "\n",
    "* **Products used:** \n",
    "[gm_s2_annual](https://explorer.digitalearth.africa/gm_s2_annual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://registry.opendata.aws/deafrica-landsat/\n",
    "\n",
    "We need to get the data for training the model as to get fit with, so that it can better predict the new test data that we feed later with high accuracy.\n",
    "We will be using crop_training_egypt.geojson data for training the model. We use collect_training_data, a custom method from the Deafrica_tools package. This extracts the data that are geometry data type and is polygon specific. This function requires query parameters, zonal_stats(mean,max,min), feature layer function as parameters. Based on these params the data will be fetched and will be written into the physical file in the disk.\n",
    "\n",
    "References\n",
    "[Maxell et al 2018](https://www.tandfonline.com/doi/full/10.1080/01431161.2018.1433343)\n",
    "[Geo-Wiki](https://www.geo-wiki.org/)\n",
    "[Collect Earth Online](https://collect.earth/home)\n",
    "[Radiant Earth](https://www.radiant.earth/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "We run the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import subprocess as sp\n",
    "import geopandas as gpd\n",
    "from odc.io.cgroups import get_cpu_quota\n",
    "from datacube.utils.geometry import assign_crs\n",
    "\n",
    "from deafrica_tools.plotting import map_shapefile\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.classification import collect_training_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "\n",
    "* `path`: The path to the input vector file from which we will extract training data. A default geojson is provided.\n",
    "* `field`: This is the name of column in your shapefile attribute table that contains the class labels. **The class labels must be integers**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/crop_training_egypt.geojson' \n",
    "field = 'class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the number of CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncpus = 2\n"
     ]
    }
   ],
   "source": [
    "ncpus=round(get_cpu_quota())\n",
    "print('ncpus = '+str(ncpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview input data\n",
    "\n",
    "We can load and preview our input data shapefile using `geopandas`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((26.19189 22.06193, 26.19230 22.06193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((32.24947 22.07338, 32.24989 22.07338...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((32.62301 22.15862, 32.62342 22.15862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((28.35345 22.29337, 28.35386 22.29337...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((27.72311 22.83994, 27.72352 22.83994...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                           geometry\n",
       "0      0  POLYGON ((26.19189 22.06193, 26.19230 22.06193...\n",
       "1      0  POLYGON ((32.24947 22.07338, 32.24989 22.07338...\n",
       "2      0  POLYGON ((32.62301 22.15862, 32.62342 22.15862...\n",
       "3      0  POLYGON ((28.35345 22.29337, 28.35386 22.29337...\n",
       "4      0  POLYGON ((27.72311 22.83994, 27.72352 22.83994..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load input data shapefile\n",
    "input_data = gpd.read_file(path)\n",
    "\n",
    "# Plot first five rows\n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569df0d41d6349aa918e042b939acd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d0a39477994c84b58f6ddb39ef3088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[26.769110088616873, 29.937057490950004], controls=(ZoomControl(options=['position', 'zoom_in_text'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training data in an interactive map\n",
    "map_shapefile(input_data, attribute=field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up our inputs to collect_training_data\n",
    "zonal_stats = 'mean'\n",
    "\n",
    "# Set up the inputs for the ODC query\n",
    "time = ('2019')\n",
    "measurements =  ['blue','green','red','nir','swir_1','swir_2','red_edge_1',\n",
    "                 'red_edge_2', 'red_edge_3', 'BCMAD', 'EMAD', 'SMAD']\n",
    "resolution = (-20,20)\n",
    "output_crs='epsg:6933'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a datacube query object from the parameters above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'time': time,\n",
    "    'measurements': measurements,\n",
    "    'resolution': resolution,\n",
    "    'output_crs': output_crs\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining feature layers\n",
    "\n",
    "To create the desired feature layers, we pass instructions to `collect_training_data` through the `feature_func` parameter.\n",
    "\n",
    "* `feature_func`: A function for generating feature layers that is applied to the data within the bounds of the input geometry. The `feature_func` must accept a `dc_query` dictionary, and return a single `xarray.Dataset` or `xarray.DataArray` containing 2D coordinates (i.e x, y - no time dimension). e.g.\n",
    "\n",
    "          def feature_function(query):\n",
    "              dc = datacube.Datacube(app='feature_layers')\n",
    "              ds = dc.load(**query)\n",
    "              ds = ds.mean('time')\n",
    "              return ds\n",
    "\n",
    "Below, we will define a more complicated feature layer function than the brief example shown above. We will calculate some band indices on the Sentinel-2 [geoMAD](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks/blob/master/Datasets/GeoMAD.ipynb) and append a slope dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.testutils.io import rio_slurp_xarray\n",
    "\n",
    "def feature_layers(query):\n",
    "    #connect to the datacube\n",
    "    dc = datacube.Datacube(app='feature_layers')\n",
    "    \n",
    "    #load s2 annual geomedian\n",
    "    ds = dc.load(product='gm_s2_annual',\n",
    "                 **query)\n",
    "    \n",
    "    #calculate some band indices\n",
    "    da = calculate_indices(ds,\n",
    "                           index=['NDVI', 'LAI', 'MNDWI'],\n",
    "                           drop=False,\n",
    "                           collection='s2')\n",
    "    \n",
    "    #add slope dataset\n",
    "    url_slope = \"https://deafrica-input-datasets.s3.af-south-1.amazonaws.com/srtm_dem/srtm_africa_slope.tif\"\n",
    "    slope = rio_slurp_xarray(url_slope, gbox=ds.geobox)\n",
    "    slope = slope.to_dataset(name='slope')\n",
    "    \n",
    "    #merge results into single dataset \n",
    "    result = xr.merge([da, slope],compat='override')\n",
    "\n",
    "    return result.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the `collect_training_data` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking zonal statistic: mean\n",
      "Collecting training data in parallel mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6e7391aec148e4997682b427c9fe3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_names, model_input = collect_training_data(\n",
    "                                    gdf=input_data,\n",
    "                                    dc_query=query,\n",
    "                                    ncpus=ncpus,\n",
    "                                    field=field,\n",
    "                                    zonal_stats=zonal_stats,\n",
    "                                    feature_func=feature_layers\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the name and location of the output file\n",
    "output_file = \"results/test_training_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab all columns\n",
    "model_col_indices = [column_names.index(var_name) for var_name in column_names]\n",
    "#Export files to disk\n",
    "np.savetxt(output_file, model_input[:, model_col_indices], header=\" \".join(column_names), fmt=\"%4f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.5\n"
     ]
    }
   ],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Tested:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-05-04'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
